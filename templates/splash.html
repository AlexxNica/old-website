<div class="jumbotron-info">
  <div class="container">
    <div class="row">
      <div class="col-md-6">
        <h1 class="jumbotron-title">Fork and sync datasets</h1>
        <div class="jumbotron-horizontal-rule"></div>
        <div class="jumbotron-description">Dat is a version-controlled, decentralized data sync tool for collaboration between data people and data systems.
        <div class="header-continue">
          <a href="http://try-dat.com" target="_blank">
            <div class="button">Try dat in your browser &rsaquo; </div>
          </a>
            <a href="https://tinyletter.com/datdata" target="_blank">
                <div class="button">Sign up for our newsletter &rsaquo; </div>
              </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
<div class="container">
<div class="row">
<div class="content-title">Versioned data storage: .csv is sooo 1995</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-4">
  <p>Import data as json or csv, parsing the data into rows. Each row is versioned with a unique key. Update row data by providing that same key.</p>
</div>
<div class="col-md-8">
  <ul class="nav nav-tabs tabs">
    <li class="active"><a href="#bash-1">cmdline</a></li>
    <li><a href="#R-1">R</a></li>
    <li><a href="#python-1">python</a></li>
  </ul>
  <div class="tab-content">
    <div id="bash-1" class="tab-pane active">
<pre><code class="bash">$ dat import values_per_city.csv --key=cityId -d cities
Added 302,143 rows (32.03 Mb, 4.4 Mb/s).
Current version is now bad31c32432c.

$ dat import values_per_city_new.csv --key=cityId -d cities
Updated 33 rows (32.03 Mb, 4.4 Mb/s).
Current version is now cef3221asd1.</code></pre>
    </div>
    <div id="R-1" class="tab-pane">
<pre><code class="r">repo <- dat("cars", path=getwd())

# import data from a dataframe
cities <- read.csv(file='cities.csv')
v1 <- repo$insert(cities[1:20,])

# get data into a dataframe at given version
v1_data <- repo$get(v1)
</code></pre>
    </div>
    <div id="python-1" class="tab-pane">
<pre><code class="python">dataset = Dataset(dat, "cities")

# import data from pandas
df = pd.DataFrame.read_csv("cities.csv")
v2 = dataset.import_dataframe(df, key="cityId")

# get data into a pandas dataframe at given version
df = dataset.export_dataframe(checkout=v1)
</code></pre>
    </div>
  </div>
</div>
</div>
</div>

<div class="row">
<div class="content-title">To parse or not to parse? Either way, it's okay.</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-4">
<p>Dat can <strong>write binary data</strong> (e.g., files). Dat stores and versions the entire file as one value.</p>
</div>
<div class="col-md-8">
  <ul class="nav nav-tabs tabs">
    <li class="active"><a href="#bash-2">cmdline</a></li>
    <li><a href="#R-2">R</a></li>
    <li><a href="#python-2">python</a></li>
  </ul>
  <div class="tab-content">
    <div id="bash-2" class="tab-pane active">
<pre><code class="bash">$ dat write /some/path/to/model.tar.gz
Storing model.tar.gz (8.3 Mb, 38 Mb/s).
Stored model.tar.gz successfully.
Current version is now b04adb64fdf2203
</code></pre>
    </div>
    <div id="R-2" class="tab-pane">
<pre><code class="r"># write binary data
v1 = repo.insert_binary(model_data, "city_predictions")

# read data at that version
city_predictions = dataset.read_binary("city_predictions", v1)
</code></pre>
    </div>
    <div id="python-2" class="tab-pane">
<pre><code class="python"># write binary data as a cPickle
v1 = repo.write(model, name="city_predictions")

# read data at that version
city_predictions = repo.read("city_predictions", checkout=v1)
</code></pre>
    </div>
</div>
</div>
</div>
</div>

<div class="row">
<div class="content-title">Collaborate with your data over SSH and HTTP endpoints</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-4">
<p>Dat is transport agnostic, so share your data through <strong>ssh or http</strong>. Use SSH keys for access control.</p>
</div>
<div class="col-md-8">
    <div id="bash-2">
<pre><code class="bash">$ dat clone ssh://uni.edu/maxogden/flights
Pulled 302,233 changes (93.88 Mb, 3.4 Mb/s).
Clone from remote has completed.
Current version is now c2342de3f
$ dat serve
Listening on 6442...
</code></pre>
    </div>
</div>
</div>
</div>

<div class="row">
<div class="content-title">Multiple datasets means multiple schemas</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-4">
<p>A dataset is like a SQL table or NoSQL collection. Create separate datasets to organize your data repository.</p>
</div>
<div class="col-md-8">
<pre><code class="bash">$ dat datasets
cities
flights
model_data
census</code></pre>
</div>
</div>
</div>

<div class="row">
<div class="content-title">Go back in time, modify, fork</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-4">
<p>Go to a previous version of the dataset with <strong>checkout</strong> in O(1) time. Updating an older version creates a new 'fork' in the dataset.</p>
</div>
<div class="col-md-8">
  <ul class="nav nav-tabs tabs">
    <li class="active"><a href="#bash-3">cmdline</a></li>
    <li><a href="#R-3">R</a></li>
    <li><a href="#python-3">python</a></li>
  </ul>
  <div class="tab-content">
    <div id="bash-3" class="tab-pane active">
<pre><code class="bash"># go back in time
$ dat checkout ab2342de3fadf212

# modify
$ dat import modified_data.csv -m "Capitalized city names" -d cities
Updated 33 keys (32.03 Mb, 4.4 Mb/s).
Current version is now cef3221asd1g234e. There are now 2 forks.

# see the forked version
$ dat forks
cef3221a0d1g234e - Capitalized city names
ab2342de3fadf212 - Added city metadata</code></pre>
    </div>
    <div id="R-3" class="tab-pane">
<pre><code class="r"># go back in time
data <- repo$get(checkout=v1)

# modify
repo$name <- toupper(data$name)

# create a fork
fork_version <- repo$insert(cities[1:50,], key='cityId', message='Capitalized city names')</code></pre>
    </div>
    <div id="python-3" class="tab-pane">
<pre><code class="python"># go back in time
df = dataset.export_dataframe(checkout=v1)

# modify
df['name'] = df['name'].str.upper()

# create a fork
fork_version = dataset.import_dataframe(df, key='cityId', message='Capitalized city names')</code></pre>
    </div>
</div>
</div>
</div>
</div>


<div class="row">
<div class="content-title">One thousand forks when all you need is a knife isn't irony</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-4">
<p>
Although conflicts are merged immediately by software development tools like git, dat embraces them. All collaborators will get a complete picture of the history of graph. Forks can be merged into a new version.
</p>
</div>
<div class="col-md-8">
    <div id="bash-2">
<pre><code class="bash">$ dat pull ssh://192.168.0.5:~/data
Pulled 823 changes (93.88 Mb, 3.4 Mb/s).
Pull completed successfully, you now have 2 forks.
Current version is now b04adb64fdf2203

$ dat forks
b04adb64fdf22030 - Added population density column
cef3221a0d1g234e - Capitalized city names
ab2342de3fadf212 - Added city metadata

$ dat merge cef3221a0d1g234e
</code></pre>
    </div>
</div>
</div>
</div>
</div>
<div class="secondary-info">
  <div class="container">
    <div class="row">
      <div class="col-md-6">
        <div class="content-sub-container content-code-intro">
        <div class="content-title" style="padding-top:0px">Resources & Community</div>
      <div class="content-horizontal-rule"></div>
          <h3>Videos about dat</h3>
          <ul>
            <li><a href="https://www.youtube.com/watch?v=psmtJUyZHE0">Dat at Berkeley Institute for Data Science</a></li>
            <li><a href="https://www.youtube.com/watch?v=4J9CSoQ-4-0">Community Call #3</a></li>
            <li><a href="https://www.youtube.com/watch?v=iM3Pr7tfHF0">JSConf San Francisco</a>
            <li><a href="https://www.youtube.com/embed/mN3H1fd9Bu8">Community Call #2</a></li>
            <li><a href="https://www.youtube.com/watch?v=AKpJgNoT1b8">Dat + Federated Wiki Mozilla Science Lab Demo</a></li>
          </ul>
        </div>
      </div>
      <div class="col-md-6">
        <h3>Dat 1.0 Roadmap -- Community Call #4</h3>
        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/SaWMON7MB3A?controls=0&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</div>
<div class="jumbotron-info">
<div class="container">
<div class="row centered">
<div class="col-md-6 col-sm-6 col-sm-offset-3">
<div class="content-title">Beta now available for testing</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container">
    <a href="https://github.com/maxogden/dat" target="_blank">
      <div class="button"><span class="octocat"></span>View on GitHub</div>
    </a>
    <a href="http://try-dat.com" target="_blank">
      <div class="button">Try dat in your browser &rsaquo; </div>
    </a>
  </div>
</div>
</div>
<div class="row centered">
<div class="content-title">Sponsors and supporters</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-logos">
  <a href="http://usodi.org/"><img src="/static/img/usod.png"></a>
  <a href="http://www.sloan.org/major-program-areas/digital-information-technology/data-and-computational-research/"><img src="/static/img/sloan.png"></a>
  <a href="http://www.knightfoundation.org/grants/201346305/"><img src="/static/img/knight.png"></a>
</div>
</div>
</div>
</div>
