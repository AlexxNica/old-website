<div class="jumbotron-info">
  <div class="container">
    <div class="row">
      <div class="col-md-6">
        <h1 class="jumbotron-title">Versioned data, collaborated</h1>
        <div class="jumbotron-horizontal-rule"></div>
        <div class="jumbotron-description">Dat is a version-controlled, distributed data tool designed to improve collaboration between data people and data systems. <div class="header-continue"><a href="https://github.com/maxogden/dat/blob/master/docs/whitepaper.md">Read the whitepaper  <span class="rsaquo">&rsaquo;</span></a></div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">

<div class="row centered">
<div class="content-title  ">beta now available for testing</div>
<div class="col-md-6 col-sm-6 col-sm-offset-3">
    <a href="https://github.com/maxogden/dat" target="_blank">
      <div class="button"><span class="octocat"></span><span class='hidden-mobile'>View on</span> GitHub</div>
    </a>
</div>
</div>

<div class="row centered">
<div class="content-title">Version by key</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-8 col-md-offset-2">
  <p>Add data into dat from newline-delimited json or csv. <strong>import</strong> is designed for key/value row-like, or tabular data. You can update the data later by specifying a <strong>unique key</strong> for each row.</p>
</div>
<div class="col-md-8 col-md-offset-2">
  <ul class="nav nav-tabs tabs">
    <li class="active"><a href="#bash-1">cmdline</a></li>
    <li><a href="#R-1">R</a></li>
    <li><a href="#python-1">python</a></li>
  </ul>
  <div class="tab-content">
    <div id="bash-1" class="tab-pane active">
<pre><code class="bash">$ dat init
$ dat import values_per_city.csv --key=cityId -d cities
Added 302,143 keys (32.03 Mb, 4.4 Mb/s).
Current version is now bad31c32432c.

$ dat import values_per_city_new.csv --key=cityId -d cities
Updated 33 keys (32.03 Mb, 4.4 Mb/s).
Current version is now cef3221asd1.</code></pre>
    </div>
    <div id="R-1" class="tab-pane">
<pre><code class="r">repo <- dat("cars", path=getwd())

# import data from a dataframe
cities <- read.csv(file='cities.csv')
v1 <- repo$insert(cities[1:20,])

# get data into a dataframe at given version
v1_data <- repo$get(v1)
</code></pre>
    </div>
    <div id="python-1" class="tab-pane">
<pre><code class="python">repo = datpy.Dat("cities")

# import data from pandas
df = pd.DataFrame.read_csv("cities.csv")
v2 = repo.import_dataframe(df, key="cityId")

# get data into a pandas dataframe at given version
df = repo.get_dataframe(checkout=v1)
</code></pre>
    </div>
  </div>
</div>
</div>
</div>

<div class="row centered">
<div class="content-title">Write blobs, or binary data</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-8 col-md-offset-2">
<p>
<strong>Write</strong> binary data into dat. This differs from import in that it doesn't parse the file, it just stores it as a binary attachment. Write is meant for large files, blobs, or attachments that you can't parse into rows.</p>
</div>
<div class="col-md-8 col-md-offset-2">
  <ul class="nav nav-tabs tabs">
    <li class="active"><a href="#bash-2">cmdline</a></li>
    <li><a href="#R-2">R</a></li>
    <li><a href="#python-2">python</a></li>
  </ul>
  <div class="tab-content">
    <div id="bash-2" class="tab-pane active">
<pre><code class="bash">$ dat write /some/path/to/model.tar.gz -d cities_models
Storing cities_scatter.jpg (8.3 Mb, 38 Mb/s).
Stored cities_scatter.jpg successfully.
Current version is now b04adb64fdf2203
</code></pre>
    </div>
    <div id="R-2" class="tab-pane">
<pre><code class="r"># write binary data
v1 = repo.insert_binary(model_data, "city_predictions")

# read data at that version
city_predictions = repo.read_binary("city_predictions", v1)
</code></pre>
    </div>
    <div id="python-2" class="tab-pane">
<pre><code class="python"># write binary data as a cPickle
v1 = repo.write(model, name="city_predictions")

# read data at that version
city_predictions = repo.cat("city_predictions", checkout=v1)
</code></pre>
    </div>
</div>
</div>
</div>


<div class="row centered">
<div class="content-title">Multiple Schemas</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-8 col-md-offset-2">
<p>A dataset is analogous to a sql table or a nosql collection; however, we chose not to use the language of 'table' or 'collection' because dat datasets do not support robust querying at this time. To support separate schemas, we encourage users to create many datasets.</p>
</div>
<div class="col-md-8 col-md-offset-2">
<pre><code class="bash">$ dat datasets
cities
flights
model_data
census</code></pre>
</div>
</div>
</div>

<div class="row centered">
<div class="content-title">Go back in time, modify, and fork</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-8 col-md-offset-2">
<p>After checking out a dataset to a previous point in the past, a user can still add more data. However, adding to a version that is not the latest creates a new fork in the dataset. Forks can also happen when two dats import or write different data to the same dat version.</p>
</div>
<div class="col-md-8 col-md-offset-2">
  <ul class="nav nav-tabs tabs">
    <li class="active"><a href="#bash-3">cmdline</a></li>
    <li><a href="#R-3">R</a></li>
    <li><a href="#python-3">python</a></li>
  </ul>
  <div class="tab-content">
    <div id="bash-3" class="tab-pane active">
<pre><code class="bash"># go back in time
$ dat checkout ab2342de3fadf212

# modify
$ dat import modified_data.csv -m "Capitalized city names" -d cities
Updated 33 keys (32.03 Mb, 4.4 Mb/s).
Current version is now cef3221asd1g234e. There are now 2 forks.

# see the forked version
$ dat forks
cef3221a0d1g234e - Capitalized city names
ab2342de3fadf212 - Added city metadata</code></pre>
    </div>
    <div id="R-3" class="tab-pane">
<pre><code class="r"># go back in time
data <- repo$get(checkout=v1)

# modify
repo$name <- toupper(data$name)

# create a fork
fork_version <- repo$insert(cities[1:50,], key='cityId', message='Capitalized city names')</code></pre>
    </div>
    <div id="python-3" class="tab-pane">
<pre><code class="python"># go back in time
df = repo.as_dataframe(checkout=v1)

# modify
df['name'] = df['name'].str.upper()

# create a fork
fork_version = repo.import_dataframe(df, key='cityId', message='Capitalized city names')</code></pre>
    </div>
</div>
</div>
</div>
</div>


<div class="row centered">
<div class="content-title">One thousand forks when all you need is a knife isn't irony</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-8 col-md-offset-2">
<p>
Although conflicts are merged immediately by software development tools like git, dat embraces conflicts -- called forks -- as key to experimentation during the scientific process. When a user pulls new data from a peer, forks will also be replicated so that each user has a complete picture of the graph. Forks can still be merged into a single, new commit to create a new version hash.
</p>
</div>
<div class="col-md-8 col-md-offset-2">
    <div id="bash-2">
<pre><code class="bash">$ dat pull ssh://192.168.0.5:~/data
Pulled 823 changes (93.88 Mb, 3.4 Mb/s).
Pull completed successfully, you now have 2 forks.
Current version is now b04adb64fdf2203

$ dat forks
b04adb64fdf22030 - Added population density column
cef3221a0d1g234e - Capitalized city names
ab2342de3fadf212 - Added city metadata

$ dat merge cef3221a0d1g234e
</code></pre>
    </div>
</div>
</div>
</div>

<div class="row centered">
<div class="content-title">SSH and HTTP endpoints</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-code-intro row">
<div class="col-md-8 col-md-offset-2">
<p>Dat is transport agnostic, but there are clients for popular transports like <strong>http or ssh</strong>. You can also pipe it or add it to an existing server.</p>
</div>
<div class="col-md-8 col-md-offset-2">
    <div id="bash-2">
<pre><code class="bash">$ dat clone ssh://uni.edu/maxogden/flights
Pulled 302,233 changes (93.88 Mb, 3.4 Mb/s).
Clone from remote has completed.
Current version is now c2342de3f
</code></pre>
    </div>
</div>
</div>
</div>
<div class="row">
<div class="content-title  centered">beta now available for testing</div>
<div class="col-md-6 col-sm-6 col-sm-offset-3">
    <a href="https://github.com/maxogden/dat" target="_blank">
      <div class="button"><span class="octocat"></span><span class='hidden-mobile'>View on</span> GitHub</div>
    </a>
</div>
</div>
<div class="row centered">
<div class="content-title">Sponsors and supporters</div>
<div class="content-horizontal-rule"></div>
<div class="content-sub-container content-logos">
  <a href="http://www.sloan.org/major-program-areas/digital-information-technology/data-and-computational-research/"><img src="/static/img/sloan.png"></a>
  <a href="http://www.knightfoundation.org/grants/201346305/"><img src="/static/img/knight.png"></a>
  <a href="http://usodi.org/"><img src="/static/img/usodi.png"></a>
</div>
</div>
