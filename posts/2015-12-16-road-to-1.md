# The Road To Dat 1.0
by [Max Ogden](http://maxogden.com)

We have some exciting news to share about Dat: We're working on a 1.0 release! It's not out just yet, but you can try what we have so far by checking out [the `master` branch on GitHub](https://github.com/maxogden/dat) or with `npm install dat@next -g`.

I'd like to explain the history of the project and the design choices over the last 2 years since the project started, as the 1.0 design represents a pretty substantial change in direction for the project.

## Dat Prototype

The original use case for Dat centered around tabular datasets that change often. We wanted to make something to simplify the process of updating your copy of the data when the publisher updates the source data. The prototype version of Dat was built over the course of 6 months and was completed in Spring of 2014.

The prototype `dat` command-line tool only worked with tabular data and usage looked like this:

```sh
dat init
echo '{"hello": "world"}' | dat --json # put a JSON object into dat
cat some_csv.csv | dat --csv # stream a CSV into dat
echo $'a,b,c\n1,2,3' | dat --csv --primary=a # specify a primary key to use
dat cat # stream the most recent of all rows
dat push http://mydat.myserver.com:6461
```

In addition to `dat push` there was also `dat clone` and `dat pull`.

## Dat Alpha

The Dat Alpha version was [released in August of 2014](https://usopendata.org/2014/08/19/dat-alpha/). The major feature we worked on was support for syncing large, non-tabular data files. This opened up a new use case: using Dat as a sort of 'DropBox for data' to sync a folder on your filesystem. With the Alpha CLI we attempted to support both the tabular *and* file syncing use cases, which increased the API surface area quite a bit:

```
dat cat
dat export
dat import
dat init
dat help
dat version
dat pull
dat push
dat clean
dat clone
dat serve
dat listen
dat blobs get
dat blobs put
dat rows get
dat rows delete
dat rows put
```

The Alpha release was the first release after starting on a new grant that shifted our focus from open civic datasets (which tend to be tabular -- e.g. lots of database tables) to the field of data intensive scientific research, which tends to use domain specific flat-file based data formats.

We worked directly, starting during the time of the Alpha and continuing on through to today, with some amazing research labs in fields like Astrophysics, Bioinformatics and Neuroscience to try and understand their data management problems. The addition of large file support in the Alpha was a direct result of getting feedback from these scientific pilot users.

## Dat Beta

