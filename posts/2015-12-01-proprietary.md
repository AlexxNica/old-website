# Proprietary services deemed harmful for open science.
by [Karissa McKelvey](http://karissa.github.io)

**Proprietary services such as GitHub, Dropbox, PLOS, Figshare, and AWS provide data hosting at little-to-no charge. They pride themselves on the ease of sharing digital materials, positioning themselves as the most popular platforms for scientific collaboration. However, each falls victim to the plight of proprietary services -- when the money runs out, so does your data.**

Imagine a scenario thirty years in the future, when most of the world's scientific data has been hosted on GitHub. Imagine that something terrible happens, and the company stops hosting data. How many owners of those open data repositories will take the time to re-host their data? How many university-hosted GitHub's will quickly become unsustainable? How many papers will be referencing dead links? Who will provide a redirect service to those new repositories? I can imagine a variety of ways in which this scenario leads to a reproducibility nightmare, even worse when confronted with the horror of losing a giant such as Amazon, Google Spreadsheets, or DropBox.

It is expected that some, or most of these companies won't exist in fifty years. The average lifespan of a company has decreased from 67 years in the 1920s to just [15 years today](http://www.bbc.com/news/business-16611040). That means that if Newton published his Law of Gravitation on DropBox in 1666, someone would have had to move the digitalÂ copy anywhere from 11 to 33 times. Sound familiar? In practice, this is what actual libraries do. Although perhaps not good for business, copying is the only sure way to create redundancy in case of disaster (corporate or otherwise).

Copying paper, as in copying data, is relatively free at first, but becomes cumbersome at scale. However, society spends a large amount of resources backing up paper (and digital) records in literal [mountains made of iron](http://www.ironmountain.com/). For decades, people have been copying vital information onto microfilm, hardy material that has a life expectancy of [a few hundred years](https://en.wikipedia.org/wiki/Microform). Where is the equivalent for open scientific data?

As we use an internet that depends increasingly on proprietary services, the implications for digital scientific data could be grim. As we encourage the publicizing of open data, we need to concern ourselves heavily with the method -- and that's where dat can come in. We're convinced that decentralized, open source tools are the right way forward to ensure longevity in data publishing. More importantly, it is crucial that *copying data* from the hosting service should not be prevented or require external tooling, as is the case with many proprietary hosting services. *Scientific pen data tools should expect, by design, editing, copying, rehosting, and redistributing the data for maximum redundancy.* Proprietary, corporate tools with business models focusing on the current fiscal quarter simply do not have the incentive structures to do this on their own.

## But how did we get here in the first place?

Proprietary services use code that is closed source. Their business model depends heavily upon preventing users from running their own copy of the software and data. The service they offer is explicitly to enclose on, or privatize, the data hosting, so that users must depend upon them. However, universities and other organizations  often purchase private installations for GitHub, Dropbox, or Box. Even in this case, though, users may not copy, distribute, study, change, or improve the software without prior permission.

![notreproducible](/static/img/notreproducible.png)

Even if the hosting service prides itself on its ease of data transfer, it can still take tremendous effort to move data off of a proprietary service. Amazon encourages users by making it free to upload data to cloud storage, but it costs money every time it needs to be downloaded. Although unfortunate, this market landscape is not necessarily the fault of companies (a topic for a different blog post). We just need to create open source alternatives and teach libraries how to use them. And we are -- albeit still falling behind Silicon Valley's immense trove of resources.

## Start here: public knowledge is a commons, not for privatization

I want to be clear -- a service should not be considered harmful just because it is a business. I don't want to create a pitchfork movement against all business hosting services (free as in freedom, not beer). I simply want to point out that, in open scientific publishing, we need to start supporting and using services that are open source (non-proprietary). In other words, let's use internet infrastructure that doesn't rely on proprietary data hosting as a business model. Brewster Khale of the Internet Archive has called for an [internet that has openness 'locked' into how it works and operates](http://brewster.kahle.org/2015/08/11/locking-the-web-open-a-call-for-a-distributed-web-2/). We support this notion, hoping that we avoid a situation where published scientific data is lost forever. We have started by designing a publishing infrastructure that is copy- and edit-friendly from the beginning.

We have to start thinking about the data we publish as part of the public sphere. Libraries are, as they always have been, in the best position to be shepherds of the knowledge in the public sphere. As scientific publishing becomes more open, and more digital, we are losing one of the main tenants that libraries have always been tasked with -- the preservation of the knowledge commons, that is, the public knowledge of our society. Private interests have begun taking over this job, but they are incorrectly equipped and incentivized for this kind of work. If you want to read more about this topic, I highly recommend reading the work of the late Eleanor Ostrom and Charolotte Hess on commons management, []**Understanding the Knowledge Commons**](https://mitpress.mit.edu/books/understanding-knowledge-commons).

It is not surprising though, as business interests are able to secure more finances than libraries in the current economy. The good news, though, is that digital scientific publishing is still young, and the lack of tooling, knowledge, and resources available in open source has improved steadily since I first heard of this problem in 2011, and hopefully only improve with time and effort. Let's start supporting libraries (as in institutions, not code) and help them power themselves with open source software. Next, we'll talk about decentralization.


Karissa McKelvey<br>
[http://karissa.github.io](http://karissa.github.io)<br>[@captainkmac on Twitter](http://twitter.com/captainkmac)
